# ðŸ“˜ Document Q&A Agent with LangChainJS + React + Tailwind

This project builds a local web app where users can **upload documents** (PDFs) and **chat with an AI agent** that answers only from the uploaded content.  
It uses **LangChainJS** to handle embeddings, vector storage, retrieval, and chaining with LLMs (OpenAI or Ollama).  

---

## ðŸ”„ Flow

1. **Upload Document** â†’ React sends file to Express backend.  
2. **Parse Document** â†’ extract text using `pdf-parse` or LangChain `PDFLoader`.  
3. **Chunk Text** â†’ split into ~500â€“1000 tokens with overlap (`RecursiveCharacterTextSplitter`).  
4. **Embeddings** â†’ convert chunks to vectors with:  
   - OpenAI: `text-embedding-3-small`  
   - Ollama: `nomic-embed-text`  
5. **Vector Store** â†’ store embeddings in **ChromaDB**.  
6. **Retriever** â†’ search top-k chunks for each query.  
7. **LangChain Chain/Agent** â†’ feed retrieved chunks + userâ€™s question into a **RetrievalQAChain** (or Agent with tools).  
8. **Generative LLM** â†’  
   - OpenAI (`gpt-4o-mini`, `gpt-3.5-turbo`)  
   - Ollama (`mistral`, `llama2`, `gemma`)  
9. **Frontend Streaming** â†’ deliver answer token-by-token in a React + Tailwind chat UI.  

---

## ðŸ›  Tech Stack

### Backend
- `express` â†’ API routes  
- `multer` â†’ file uploads  
- `pdf-parse` â†’ extract text  
- `langchain` â†’ splitters, embeddings, vector store, chains  
- `chromadb` â†’ local vector DB  
- `openai` â†’ API client (if using OpenAI)  
- `node-fetch` â†’ call Ollama API  
- `dotenv` â†’ manage API keys  

### Frontend
- `react` + `vite` â†’ UI  
- `axios` â†’ API requests  
- `tailwindcss` â†’ styling  
- `EventSource` â†’ handle streaming responses  

---
 